{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-07 12:14:18,298] [TfPoseEstimator] [INFO] loading graph from /home/yinghuit/Documents/tf-pose-estimation/models/graph/cmu/graph_opt.pb(default size=432x368)\n",
      "I1007 12:14:18.298104 140534574683968 estimator.py:310] loading graph from /home/yinghuit/Documents/tf-pose-estimation/models/graph/cmu/graph_opt.pb(default size=432x368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from tf_pose import common\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "if w == 0 or h == 0:\n",
    "    e = TfPoseEstimator(get_graph_path('cmu'), target_size=(432, 368))\n",
    "else:\n",
    "    e = TfPoseEstimator(get_graph_path('cmu'), target_size=(w, h))\n",
    "\n",
    "image = common.read_imgfile('./images/p2.jpg', None, None)\n",
    "image_h, image_w = image.shape[:2]\n",
    "t = time.time()\n",
    "humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=4.0)\n",
    "elapsed = time.time() - t\n",
    "log = []\n",
    "for human in humans:\n",
    "    centers = {}\n",
    "    for i in range(common.CocoPart.Background.value):\n",
    "        if i not in human.body_parts.keys():\n",
    "            continue\n",
    "        body_part = human.body_parts[i]\n",
    "        center = (int(body_part.x * image_w + 0.5), int(body_part.y * image_h + 0.5))\n",
    "        centers[i] = center\n",
    "    log.append(centers)\n",
    "\n",
    "print(len(humans))\n",
    "img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: (354, 84),\n",
       "  1: (360, 130),\n",
       "  2: (314, 140),\n",
       "  3: (302, 212),\n",
       "  4: (326, 244),\n",
       "  5: (406, 122),\n",
       "  6: (442, 192),\n",
       "  7: (392, 248),\n",
       "  8: (336, 250),\n",
       "  9: (260, 280),\n",
       "  10: (310, 400),\n",
       "  11: (408, 254),\n",
       "  12: (342, 288),\n",
       "  13: (354, 408),\n",
       "  14: (344, 76),\n",
       "  15: (364, 76),\n",
       "  16: (330, 88),\n",
       "  17: (378, 88)},\n",
       " {0: (136, 78),\n",
       "  1: (138, 120),\n",
       "  2: (94, 130),\n",
       "  3: (84, 196),\n",
       "  4: (106, 224),\n",
       "  5: (182, 112),\n",
       "  6: (216, 178),\n",
       "  7: (170, 228),\n",
       "  8: (118, 232),\n",
       "  9: (44, 260),\n",
       "  10: (90, 374),\n",
       "  11: (184, 234),\n",
       "  12: (120, 266),\n",
       "  13: (134, 386),\n",
       "  14: (126, 70),\n",
       "  15: (146, 70),\n",
       "  16: (108, 74),\n",
       "  17: (154, 76)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Draw Human Pose Centers and Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "image_h = 1080\n",
    "image_w = 1920\n",
    "jsonstring = '[{16: (1690, 790), 2: (1684, 802), 3: (1678, 812), 4: (1696, 796)}, {1: (1902, 320), 8: (1904, 340), 9: (1900, 360), 10: (1896, 374), 11: (1904, 340), 12: (1902, 360), 13: (1896, 372)}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{16: (1690, 790), 2: (1684, 802), 3: (1678, 812), 4: (1696, 796)}, {1: (1902, 320), 8: (1904, 340), 9: (1900, 360), 10: (1896, 374), 11: (1904, 340), 12: (1902, 360), 13: (1896, 372)}]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.common import CocoPart\n",
    "\n",
    "img = np.zeros([image_h,image_w,3],dtype=np.uint8)\n",
    "img.fill(0)\n",
    "log = eval(jsonstring)\n",
    "print(log)\n",
    "print(len(log))\n",
    "for obj in log:\n",
    "    for k, v in obj.items():\n",
    "        cv2.circle(img, v, 3, common.CocoColors[k], thickness=3, lineType=8, shift=0)\n",
    "    for pair_order, pair in enumerate(common.CocoPairsRender):\n",
    "        if pair[0] not in obj.keys() or pair[1] not in obj.keys():\n",
    "            continue\n",
    "        cv2.line(img, obj[pair[0]], obj[pair[1]], common.CocoColors[pair_order], 3)\n",
    "cv2.imshow('draw', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
