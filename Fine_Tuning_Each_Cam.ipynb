{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Pose Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to fine tune the target size of each of the 15 camera feeds we are processing to eliminate the false positives in the final human detection.\n",
    "\n",
    "The reszie factor was adjusted accordingly to meet the aim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is detected\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodlogy for Optimising the Resize Factor\n",
    "\n",
    "- Trial and error to minimise the false positive (eg. Wall painting identified as person when it's dark) while keeping the detection rate at optimum level.\n",
    "\n",
    "- Test on both daylight and night footage for each cameras.\n",
    "\n",
    "- Conducted a quick check on the pre-optimised datasets. \n",
    "\n",
    "- Based on the results, here's the result with the camera detected the most number of skeletons at low activity hours (22:00 - 05:00) in **DESCENDING** order.\n",
    "    - [ ] CAM 3 \n",
    "    - [x] CAM 16\n",
    "    - [x] CAM 11 \n",
    "    - [x] CAM 2\n",
    "    - [ ] CAM 7\n",
    "    - [ ] CAM 1\n",
    "    - [ ] CAM 4\n",
    "    - [ ] CAM 14\n",
    "    - [ ] CAM 12\n",
    "    - [ ] CAM 6\n",
    "    - [ ] CAM 9\n",
    "    - [ ] CAM 8\n",
    "    - [ ] CAM 15\n",
    "    - [ ] CAM 5\n",
    "    - [ ] CAM 10\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:48:04.182468Z",
     "start_time": "2019-10-15T09:47:39.279978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 20:58:15,510] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1120x720)\n",
      "2019-10-16 20:58:15,510 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1120x720)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam01_20191015.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(1120, 720))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daylight Footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 20:28:14,664] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n",
      "2019-10-16 20:28:14,664 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam02_20191010.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(940, 720))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Night Footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 20:58:58,134] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n",
      "2019-10-16 20:58:58,134 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam02_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(940, 720))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 3 (NEED TO COLLECT DAYLIGHT FOOTAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Night Footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:13:47,422] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n",
      "2019-10-16 21:13:47,422 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=940x720)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam03_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(940, 720))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:39:26,600] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x720)\n",
      "2019-10-16 21:39:26,600 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x720)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam04_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(960, 720))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:53:11,524] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=720x540)\n",
      "2019-10-16 21:53:11,524 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=720x540)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam06_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(720, 540))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/mobilenet/mobilenet.py:369: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:52:52,171] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=720x540)\n",
      "2019-10-16 21:52:52,171 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=720x540)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:311: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,172 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:311: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:312: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,172 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:312: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:330: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,185 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:330: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,267 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:341: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,434 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:341: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:342: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,435 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:342: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/tensblur/smoother.py:96: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,440 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/tensblur/smoother.py:96: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-16 21:52:52,448 WARNING From /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/tf_pose/estimator.py:354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam07_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(720, 540))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam07_footage', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T09:54:46.200521Z",
     "start_time": "2019-10-15T09:53:10.626055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:33:01,817] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1080x760)\n",
      "2019-10-16 21:33:01,817 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1080x760)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam11_20191010.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(1080, 760))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:11:52,403] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1200x840)\n",
      "2019-10-16 21:11:52,403 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=1200x840)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam11_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(1200, 840))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:55:34,680] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x640)\n",
      "2019-10-16 21:55:34,680 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x640)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam14_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(960, 640))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daylight with People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T10:31:59.638000Z",
     "start_time": "2019-10-15T10:28:12.724449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 22:00:12,903] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x540)\n",
      "2019-10-16 22:00:12,903 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x540)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam16_20191015.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(960, 540))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-16 21:58:47,351] [TfPoseEstimator] [INFO] loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x540)\n",
      "2019-10-16 21:58:47,351 INFO loading graph from /home/josephkchin/MEGA/Lauretta/tf-pose-estimation/models/graph/mobilenet_v2_large/graph_opt.pb(default size=960x540)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cap = cv2.VideoCapture('SIT_Footage/cam16_20191015_night.mp4')\n",
    "\n",
    "w, h = model_wh('0x0')\n",
    "e = TfPoseEstimator(get_graph_path(\"mobilenet_v2_large\"), target_size=(960, 540))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image = cap.read()\n",
    "    if image is None:\n",
    "        break\n",
    "        \n",
    "    image_h, image_w = image.shape[:2]\n",
    "    humans = e.inference(image, resize_to_default=True, upsample_size=4.0)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "    \n",
    "    cv2.imshow('cam', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-pose]",
   "language": "python",
   "name": "conda-env-tf-pose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
